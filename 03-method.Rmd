---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Methods
```{r setup}
library(tidyverse)
library(readxl)
library(ggplot2)
library(ggpmisc)
library(scales)
library(DT)
library(dplyr)
library(devEMF)
```

We describe our methods in this chapter.


```{r kalman_function}
#' Function to compute estimated queue length via a Kalman filter
#'
#' @param v_in vector of vehicles entering queue in time 
#' @param v_out vector of vehicles entering queue in time 
#' @param K Coefficient of 
#' @param period_length in minutes
#' @param ramp_length Length of the ramp in feet
#' @param n_lanes Number of lanes on ramp.
#' @param veh_length Average assumed vehicle length with safety buffer
#' 
kalman_filter <- function(v_in, v_out, occupancy, K = 0.22, C = NA, period_length = 1,
                          ramp_length, n_lanes = 2, veh_length = 24){
  

    # estimate of queue based on density
  qhat <- (occupancy/100) * ramp_length * n_lanes / veh_length
  
  # conservation model of queue length - C is a factor of the total error between
  # in and out
  if(is.na(C)) {
      C <- sum(v_in) / sum(v_out)
  }

  conservation <- period_length * (v_in - C * v_out)
  
  # loop through periods
  queue <- rep(0, length(v_in)) # create a vector of zeros to store everything
  for (i in 1:length(v_in)){
    lastqueue <- if(i == 1) 0 else queue[i-1]
    queue[i] <- lastqueue + conservation[i] + K * (qhat[i] - lastqueue)
    
  }

  # queue must be non-negative
  ifelse(queue < 0, queue, queue)
}
```


## Data
Read in the data. 

```{r load_data}
layton <- read_excel("data/layton_counts.xlsx")
# read data from other places later.


detector <- layton %>%
  select(Start_time, Queue_size, contains("Manual"),
         contains("Auto"), EQ_1_Occ, EQ_2_Occ)  %>%
  mutate(
    v_in = Auto_EQ_1 + Auto_EQ_2 + Auto_EQ_3,
    v_out = Auto_Pass_1 + Auto_Pass_2,
    occupancy = (EQ_1_Occ + EQ_2_Occ)/ 2,
    Manual_EQ_Tot = Manual_EQ_1 + Manual_EQ_2 + Manual_EQ_3,
    Detector_EQ_Tot = Auto_EQ_1 + Auto_EQ_2 + Auto_EQ_3
  )
  
```


This stuff might actually belong in the results / application page. But it's
here for now.

```{r kalman_apply}
# calculate kalman filter
estimated_queues <- detector %>%
  mutate(
    day = lubridate::wday(Start_time)
  ) %>%
  group_by(day) %>%
  mutate(
    kalman = kalman_filter(v_in, v_out, occupancy, ramp_length = 537)
    # here is where your other conservation goes? 
  ) %>%
  ungroup() %>%
  select(Start_time, Queue_size, kalman)
```


```{r rmse_function}
# function to compute root mean squared error between two vectors (strangely
# not in R by default)
rmse <- function(x, y){
  sqrt(mean(( x - y )^2, na.rm = TRUE))
}
```


```{r kalman_optim}
# Objective function: 
# a function that will return the RMSE between our observed and 
# and kalman-calculated queues for different values of C and K
rmse_kalman <- function(p, df){
  
  queue <- kalman_filter(df$v_in, df$v_out, df$occupancy, K = p[1], ramp_length = 537)
  # compute moving average: might want to do this ahead of time?
  #MAQueue <- (lag(queue) + queue + lead(queue))/3
  rmse(df$Queue_size, queue)
}

rmse_kalman(0.22, detector)
rmse_kalman(0,detector)

# Optimize:
# Find the values of C and K that will minimize the objective function
optim(c(0.22), rmse_kalman, df = detector)
```
```{r split}
rmse022 <- function(df){rmse_kalman(0.22, df)}

optim_k <- function(df){
  optim_results <- optim(c(0.22), rmse_kalman, df = df)
  optim_results$par
}


optim_rmse <- function(df){
  optim_results <- optim(c(0.22), rmse_kalman, df = df)
  optim_results$value
}

optim_rmse(detector)

optimal_values <- detector %>%
  mutate(dow = lubridate::day(`Start_time`)) %>%
  group_by(dow) %>%
  nest() %>%
  mutate(
    rmse_at_22 = map_dbl(data, rmse022),
    optim_k = map_dbl(data, optim_k),
    optim_rmse = map_dbl(data, optim_rmse)
    
  )
```

```{r layton EQ, warning=FALSE, message=FALSE, results=FALSE}

# Compare EQ Detector and Manual Counts
formula1 <- y ~ x
eq1 <- ggplot(detector,aes(Manual_EQ_Tot,Detector_EQ_Tot)) + geom_jitter() +  
  xlab("EQ Manual Count Volume (veh/min)") + ylab("EQ Detector Volume (veh/min)") +
  geom_smooth(method="lm",se=FALSE) +
  stat_poly_eq(formula=formula1,aes(label=paste(..eq.label..,..rr.label..,sep="~~~")),parse=TRUE) + 
  scale_x_continuous(breaks=c(0,5,10,15,20,25))
  scale_y_continuous(breaks=c(0,5,10,15,20,25))
  print(eq1)
```

```{r layton Manual vs. Conservation Model, warning=FALSE, message=FALSE}

detector %>% 
  mutate(day = lubridate::day(Start_time)) %>%
  left_join(optimal_values %>% select(day = dow, optim_k), by = "day") %>%
  group_by(day) %>%
  transmute(`Start time` = Start_time, 
            Model = kalman_filter(v_in, v_out, occupancy, K = 0, ramp_length = 537),
            Manual = Queue_size) %>%
 gather(key = "Legend", value = "Queue Size", -`Start time`, -day)  %>%
ggplot(aes(x = `Start time`, y = `Queue Size`, color = `Legend`)) + 
  geom_line() +
  facet_wrap(~day, scales = "free") +
  ggtitle("Manual vs Estimated Counts Using Conservation Model") +
  scale_y_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20,22,24)) 
```

```{r layton Manual vs. Kalman Filter Model, warning=FALSE, message=FALSE}

detector %>% 
  mutate(day = lubridate::day(Start_time)) %>%
  left_join(optimal_values %>% select(day = dow, optim_k), by = "day") %>%
  group_by(day) %>%
  transmute(`Start time` = Start_time, 
            Model = kalman_filter(v_in, v_out, occupancy, K = optim_k[1], ramp_length = 537),
            Manual = Queue_size,
            day = str_c(day, ", k = ", round(optim_k, 4))) %>%
 gather(key = "Legend", value = "Queue Size", -`Start time`, -day)  %>%
ggplot(aes(x = `Start time`, y = `Queue Size`, color = `Legend`)) + 
  geom_line() +
  facet_wrap(~day, scales = "free") +
  ggtitle("Manual vs Estimated Counts Using Kalman Filter Model") +
  scale_y_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20,22,24))
```

